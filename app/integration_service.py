import sys
import os
import json
import time  # ğŸ”¹ ì¶”ê°€: ì‹œê°„ ì¸¡ì •ìš©
import traceback

sys.path.append(os.path.dirname(os.path.dirname(__file__)))

from config_loader import config
from modules.image_selector import ImageClusterSelector
from modules.ocr_pii import initialize_tesseract, initialize_analyzer, analyze_and_blur_image
from modules.image_description import ImageDescription, EmbeddingGenerator, VectorDBStorage
from modules.action_predictor import ActionPredictor
from modules.history_qa import HistoryQA



class IntegrationService:
    def __init__(self):
        ## ì´ˆê¸°í™” (ì‹œê°„ ì¸¡ì • ê°€ëŠ¥)
        initialize_tesseract()
        self.analyzer = initialize_analyzer()

        # ëª¨ë“ˆ ì´ˆê¸°í™”
        self.selector = ImageClusterSelector(
            n_clusters=config["image_selector"]["n_clusters"],
            random_state=config["image_selector"]["random_state"]
        )
        self.image_desc = ImageDescription(
            model_name=config["openai"]["image_description_model"]
        )
        self.embed_gen = EmbeddingGenerator(
            model_name=config["openai"]["embedding_model"]
        )
        self.db = VectorDBStorage(
            db_dir=os.path.dirname(config["vectordb"]["path"]),
            index_name=os.path.splitext(os.path.basename(config["vectordb"]["path"]))[0],
            dim=config["vectordb"]["dim"]
        )
        
        self.db.reset()

        self.action_predictor = ActionPredictor(
            model_name=config["openai"]["action_predictor_model"]
        )
        self.history_qa = HistoryQA(
            model_name=config["openai"]["history_qa_model"]
        )

        ## ì´ˆê¸°í™” ì™„ë£Œ (ì‹œê°„ ì¸¡ì • ê°€ëŠ¥)
        print("[Init ì™„ë£Œ] í†µí•© ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")

    def run_image_cycle(self, upload_dir: str):
        print(f"\nì „ì²´ ì´ë¯¸ì§€ í´ë” ì²˜ë¦¬ ì‹œì‘: {upload_dir}\n")

        start_total = time.perf_counter()  # ğŸ”¹ ì „ì²´ ì‚¬ì´í´ ì‹œì‘ ì‹œê°„

        ## 1ï¸âƒ£ ëŒ€í‘œ ì´ë¯¸ì§€ ì„ íƒ
        t1 = time.perf_counter()
        rep_img_path, all_imgs = self.selector.select(upload_dir)
        print(f"[1] ëŒ€í‘œ ì´ë¯¸ì§€ ì„ íƒ ì™„ë£Œ ({len(all_imgs)}ì¥) - {time.perf_counter() - t1:.2f}s")

        ## 2ï¸âƒ£ OCR + PII ë¶„ì„
        t2 = time.perf_counter()
        blurred_img, _ = analyze_and_blur_image(rep_img_path, self.analyzer)
        print(f"[2] OCR + PII ë¶„ì„ ì™„ë£Œ - {time.perf_counter() - t2:.2f}s")
        if blurred_img is None:
            raise ValueError("ì´ë¯¸ì§€ ì²˜ë¦¬ ì‹¤íŒ¨")

        ## 3ï¸âƒ£ ì´ë¯¸ì§€ ì„¤ëª… ìƒì„±
        t3 = time.perf_counter()
        desc_response = self.image_desc.generate_description(rep_img_path)
        description_text = desc_response.output_text.strip()
        print(f"[3] ì´ë¯¸ì§€ ì„¤ëª… ìƒì„± ì™„ë£Œ - {time.perf_counter() - t3:.2f}s")
        print(f"    â”” ìš”ì•½: {description_text[:80]}...")

        ## 4ï¸âƒ£ ì„ë² ë”© ìƒì„± ë° ì €ì¥
        t4 = time.perf_counter()
        embedding = self.embed_gen.generate_embedding(description_text)
        self.db.add_vector(embedding, {
            "file": os.path.basename(rep_img_path),
            "text": description_text
        })

        print("[FAISS] ì¸ë±ìŠ¤ ì €ì¥ ì‹œë„ ì¤‘...")
        self.db.save()
        print(f"[4] ì„ë² ë”© ìƒì„± ë° ì €ì¥ ì™„ë£Œ - {time.perf_counter() - t4:.2f}s")

        ## 5ï¸âƒ£ í´ë” ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
        t5 = time.perf_counter()
        folder_context = [os.path.basename(p) for p in all_imgs if p != rep_img_path]
        context_text = "\n".join(folder_context)
        print(f"[5] í´ë” ì»¨í…ìŠ¤íŠ¸ êµ¬ì„± ì™„ë£Œ - {time.perf_counter() - t5:.2f}s")

        ## 6ï¸âƒ£ ë²¡í„° DB ê²€ìƒ‰
        t6 = time.perf_counter()
        if self.db.metadata:
            recent_items = self.db.get_recent(k=config["vectordb"]["recent_k"])
            recent_context = recent_items[0]["text"] if recent_items else ""
            similar_results = self.db.search_vector(
                embedding,
                top_k=config["vectordb"]["search_top_k"]
            )
            similar_context = similar_results[0]["metadata"]["text"] if similar_results else ""
        else:
            recent_context, similar_context = "", ""
        print(f"[6] ë²¡í„° DB ê²€ìƒ‰ ì™„ë£Œ - {time.perf_counter() - t6:.2f}s")

        ## 7ï¸âƒ£ í–‰ë™ ì˜ˆì¸¡
        t7 = time.perf_counter()
        prompt_context = (
            f"ëŒ€í‘œ ì´ë¯¸ì§€ ì„¤ëª…:\n{description_text}\n\n"
            f"í´ë” ë‚´ ë‹¤ë¥¸ ì´ë¯¸ì§€ë“¤:\n{context_text}"
        )
        action_prediction_json = self.action_predictor.predict(
            prompt_context, recent_context, similar_context
        )
        print(f"[7] í–‰ë™ ì˜ˆì¸¡ ì™„ë£Œ - {time.perf_counter() - t7:.2f}s")

        ## ëª¨ë¸ ì›ë³¸ ì‘ë‹µ ì¶œë ¥
        print("\n[ëª¨ë¸ ì›ë³¸ ì‘ë‹µ]")
        print(repr(action_prediction_json))
        print("============================\n")

        ## 8ï¸âƒ£ JSON íŒŒì‹±
        t8 = time.perf_counter()
        try:
            raw_text = action_prediction_json.strip()
            if not raw_text:
                print("[ê²½ê³ ] action_predictionì´ ë¹„ì–´ ìˆìŒ, ê¸°ë³¸ê°’ ì„¤ì •")
                action_prediction = {"predicted_actions": [], "predicted_questions": []}
            else:
                cleaned = (
                    raw_text.replace("```json", "")
                    .replace("```", "")
                    .strip()
                )
                action_prediction = json.loads(cleaned)
        except Exception as e:
            print(f"[ê²½ê³ ] JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
            print("ì›ë³¸ ì¶œë ¥:", repr(action_prediction_json))
            action_prediction = {"predicted_actions": [], "predicted_questions": []}
        print(f"[8] JSON íŒŒì‹± ì™„ë£Œ - {time.perf_counter() - t8:.2f}s")

        ## âœ… ì „ì²´ ì²˜ë¦¬ì‹œê°„ ì¶œë ¥
        total_time = time.perf_counter() - start_total
        print(f"\nâœ… ì „ì²´ ì‚¬ì´í´ ì™„ë£Œ - ì´ {total_time:.2f}ì´ˆ ì†Œìš”\n")

        ## ê²°ê³¼ ë°˜í™˜
        return {
            "representative_image": rep_img_path,
            "description": description_text,
            "cluster_size": len(all_imgs),
            "cluster_images": folder_context,
            "predicted_actions": action_prediction.get("predicted_actions", []),
            "predicted_questions": action_prediction.get("predicted_questions", [])
        }


    def _format_ai_answer(self, user_question: str, answer: str):
        """
        ëª¨ë¸ ì‘ë‹µ(JSON or ì¼ë°˜ ë¬¸ìì—´)ì„ íŒŒì‹±í•´
        Q / AIì˜ ìƒê° / A í˜•íƒœë¡œ ë°˜í™˜.
        """
        try:
            cleaned = (
                answer.replace("```json", "")
                .replace("```", "")
                .strip()
            )
            parsed = json.loads(cleaned)
        except Exception:
            # JSON í˜•íƒœê°€ ì•„ë‹ˆë©´ fallback
            parsed = {"reasoning_steps": [], "final_answer": answer.strip()}

        reasoning_steps = parsed.get("reasoning_steps", [])
        final_answer = parsed.get("final_answer", "").strip()

        # í¬ë§· êµ¬ì„±
        if reasoning_steps:
            thoughts = "\n".join([f"{i+1}. {step}" for i, step in enumerate(reasoning_steps)])
        else:
            thoughts = "(AIì˜ ì„¸ë¶€ ì‚¬ê³  ë‹¨ê³„ ì •ë³´ê°€ ì œê³µë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.)"

        # ìµœì¢… ì¶œë ¥ êµ¬ì¡°
        return {
            "question": user_question.strip(),
            "ai_thoughts": thoughts,
            "answer": final_answer or "ë‹µë³€ì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤."
        }

    def answer_question(self, user_question: str):
        """
        ì‚¬ìš©ìì˜ ì§ˆë¬¸(user_question)ì— ëŒ€í•´, ìµœê·¼ ì´ë¯¸ì§€ ì„¤ëª… ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€ ìƒì„±.
        VectorDBì—ì„œ ìë™ìœ¼ë¡œ contextë¥¼ êµ¬ì„±í•©ë‹ˆë‹¤.
        """

        # === ì»¨í…ìŠ¤íŠ¸ ê¸°ë³¸ê°’ (ì—†ì„ ë•Œë„ í”„ë¡¬í”„íŠ¸ì—ì„œ ì²˜ë¦¬ ê°€ëŠ¥í•˜ë„ë¡ "X"ë¡œ ì„¤ì •)
        current_context = "X"
        recent_context = "X"
        similar_context = "X"

        try:
            if self.db.metadata:
                current_item = self.db.metadata[-1]
                current_context = current_item.get("text", "") or "X"

                # ìµœê·¼ ë°ì´í„°
                recent_items = self.db.get_recent(k=config["vectordb"]["recent_k"])
                recent_context = "\n\n".join(
                    [it.get("text", "") for it in recent_items if it.get("id") != current_item.get("id")]
                ).strip() or "X"

                # ìœ ì‚¬ ê²€ìƒ‰
                if current_context and current_context != "X":
                    embedding = self.embed_gen.generate_embedding(current_context)
                    similar_results = self.db.search_vector(
                        embedding,
                        top_k=config["vectordb"]["search_top_k"],
                        exclude_id=current_item["id"]
                    )
                    similar_context = "\n\n".join(
                        [r["metadata"]["text"] for r in similar_results]
                    ).strip() or "X"

            # === ëª¨ë¸ í˜¸ì¶œ
            answer = self.history_qa.answer(
                current_context=current_context,
                recent_context=recent_context,
                similar_context=similar_context,
                user_question=user_question
            )

            print("\n[ì§ˆë¬¸]")
            print(user_question)
            print("\n[ëª¨ë¸ RAW ì‘ë‹µ]")
            print(answer)

            formatted = self._format_ai_answer(user_question, answer)
            print("\n[í¬ë§·íŒ…ëœ ê²°ê³¼]")
            print(json.dumps(formatted, ensure_ascii=False, indent=2))
            return formatted

        except Exception as e:
            print(f"[ì˜¤ë¥˜] answer_question ì²˜ë¦¬ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}")
            traceback.print_exc()
            return {
                "question": user_question,
                "ai_thoughts": "(ì˜ˆì™¸ê°€ ë°œìƒí•˜ì—¬ ê¸°ë³¸ ì‘ë‹µì„ ë°˜í™˜í•©ë‹ˆë‹¤.)",
                "answer": "ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
            }



if __name__ == "__main__":
    service = IntegrationService()
    sample_dir = os.path.join(config["integration"]["sample_dir"])

    if not os.path.exists(sample_dir):
        raise FileNotFoundError(f"{sample_dir} í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤.")

    print(f"ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬: {sample_dir}\n")

    ## ë™ì¼ í´ë”ë¥¼ 3íšŒ ë°˜ë³µ ì²˜ë¦¬
    for i in range(3):
        print(f"\n=== [{i+1}íšŒì°¨ ì´ë¯¸ì§€ ì²˜ë¦¬ ì‹œì‘] ===")
        result = service.run_image_cycle(sample_dir)
        print(f"\n[{i+1}íšŒì°¨ í†µí•© ëª¨ë“ˆ ê²°ê³¼]")
        print(json.dumps(result, ensure_ascii=False, indent=2))

    ## ëª¨ë“  ì‚¬ì´í´ ì™„ë£Œ í›„ QA í…ŒìŠ¤íŠ¸ ìˆ˜í–‰
    print("\n============================")
    print("[HistoryQA í…ŒìŠ¤íŠ¸ ì‹œì‘]")
    user_question = "í˜„ì¬ ë‚˜ëŠ” ì–´ë–¤ ì¼ë“¤ì„ í•˜ê³  ìˆëŠ”ì§€ ì„¤ëª…í•´ì¤˜."
    answer = service.answer_question(user_question)
    print("\n[ìµœì¢… QA ê²°ê³¼]")
    print(answer)
