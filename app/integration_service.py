import sys
import os
import json
import time  # ğŸ”¹ ì¶”ê°€: ì‹œê°„ ì¸¡ì •ìš©

sys.path.append(os.path.dirname(os.path.dirname(__file__)))

from config_loader import config
from modules.image_selector import ImageClusterSelector
from modules.ocr_pii import initialize_tesseract, initialize_analyzer, analyze_and_blur_image
from modules.image_description import ImageDescription, EmbeddingGenerator, VectorDBStorage
from modules.action_predictor import ActionPredictor
from modules.history_qa import HistoryQA


class IntegrationService:
    def __init__(self):
        ## ì´ˆê¸°í™” (ì‹œê°„ ì¸¡ì • ê°€ëŠ¥)
        initialize_tesseract()
        self.analyzer = initialize_analyzer()

        # ëª¨ë“ˆ ì´ˆê¸°í™”
        self.selector = ImageClusterSelector(
            n_clusters=config["image_selector"]["n_clusters"],
            random_state=config["image_selector"]["random_state"]
        )
        self.image_desc = ImageDescription(
            model_name=config["openai"]["image_description_model"]
        )
        self.embed_gen = EmbeddingGenerator(
            model_name=config["openai"]["embedding_model"]
        )
        self.db = VectorDBStorage(
            db_dir=os.path.dirname(config["vectordb"]["path"]),
            index_name=os.path.splitext(os.path.basename(config["vectordb"]["path"]))[0],
            dim=config["vectordb"]["dim"]
        )
        self.action_predictor = ActionPredictor(
            model_name=config["openai"]["action_predictor_model"]
        )
        self.history_qa = HistoryQA(
            model_name=config["openai"]["history_qa_model"]
        )

        ## ì´ˆê¸°í™” ì™„ë£Œ (ì‹œê°„ ì¸¡ì • ê°€ëŠ¥)
        print("[Init ì™„ë£Œ] í†µí•© ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")

    def run_image_cycle(self, upload_dir: str):
        print(f"\nì „ì²´ ì´ë¯¸ì§€ í´ë” ì²˜ë¦¬ ì‹œì‘: {upload_dir}\n")

        start_total = time.perf_counter()  # ğŸ”¹ ì „ì²´ ì‚¬ì´í´ ì‹œì‘ ì‹œê°„

        ## 1ï¸âƒ£ ëŒ€í‘œ ì´ë¯¸ì§€ ì„ íƒ
        t1 = time.perf_counter()
        rep_img_path, all_imgs = self.selector.select(upload_dir)
        print(f"[1] ëŒ€í‘œ ì´ë¯¸ì§€ ì„ íƒ ì™„ë£Œ ({len(all_imgs)}ì¥) - {time.perf_counter() - t1:.2f}s")

        ## 2ï¸âƒ£ OCR + PII ë¶„ì„
        t2 = time.perf_counter()
        blurred_img, _ = analyze_and_blur_image(rep_img_path, self.analyzer)
        print(f"[2] OCR + PII ë¶„ì„ ì™„ë£Œ - {time.perf_counter() - t2:.2f}s")
        if blurred_img is None:
            raise ValueError("ì´ë¯¸ì§€ ì²˜ë¦¬ ì‹¤íŒ¨")

        ## 3ï¸âƒ£ ì´ë¯¸ì§€ ì„¤ëª… ìƒì„±
        t3 = time.perf_counter()
        desc_response = self.image_desc.generate_description(rep_img_path)
        description_text = desc_response.output_text.strip()
        print(f"[3] ì´ë¯¸ì§€ ì„¤ëª… ìƒì„± ì™„ë£Œ - {time.perf_counter() - t3:.2f}s")
        print(f"    â”” ìš”ì•½: {description_text[:80]}...")

        ## 4ï¸âƒ£ ì„ë² ë”© ìƒì„± ë° ì €ì¥
        t4 = time.perf_counter()
        embedding = self.embed_gen.generate_embedding(description_text)
        self.db.add_vector(embedding, {
            "file": os.path.basename(rep_img_path),
            "text": description_text
        })
        self.db.save()
        print(f"[4] ì„ë² ë”© ìƒì„± ë° ì €ì¥ ì™„ë£Œ - {time.perf_counter() - t4:.2f}s")

        ## 5ï¸âƒ£ í´ë” ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
        t5 = time.perf_counter()
        folder_context = [os.path.basename(p) for p in all_imgs if p != rep_img_path]
        context_text = "\n".join(folder_context)
        print(f"[5] í´ë” ì»¨í…ìŠ¤íŠ¸ êµ¬ì„± ì™„ë£Œ - {time.perf_counter() - t5:.2f}s")

        ## 6ï¸âƒ£ ë²¡í„° DB ê²€ìƒ‰
        t6 = time.perf_counter()
        if self.db.metadata:
            recent_items = self.db.get_recent(k=config["vectordb"]["recent_k"])
            recent_context = recent_items[0]["text"] if recent_items else ""
            similar_results = self.db.search_vector(
                embedding,
                top_k=config["vectordb"]["search_top_k"]
            )
            similar_context = similar_results[0]["metadata"]["text"] if similar_results else ""
        else:
            recent_context, similar_context = "", ""
        print(f"[6] ë²¡í„° DB ê²€ìƒ‰ ì™„ë£Œ - {time.perf_counter() - t6:.2f}s")

        ## 7ï¸âƒ£ í–‰ë™ ì˜ˆì¸¡
        t7 = time.perf_counter()
        prompt_context = (
            f"ëŒ€í‘œ ì´ë¯¸ì§€ ì„¤ëª…:\n{description_text}\n\n"
            f"í´ë” ë‚´ ë‹¤ë¥¸ ì´ë¯¸ì§€ë“¤:\n{context_text}"
        )
        action_prediction_json = self.action_predictor.predict(
            prompt_context, recent_context, similar_context
        )
        print(f"[7] í–‰ë™ ì˜ˆì¸¡ ì™„ë£Œ - {time.perf_counter() - t7:.2f}s")

        ## ëª¨ë¸ ì›ë³¸ ì‘ë‹µ ì¶œë ¥
        print("\n[ëª¨ë¸ ì›ë³¸ ì‘ë‹µ]")
        print(repr(action_prediction_json))
        print("============================\n")

        ## 8ï¸âƒ£ JSON íŒŒì‹±
        t8 = time.perf_counter()
        try:
            raw_text = action_prediction_json.strip()
            if not raw_text:
                print("[ê²½ê³ ] action_predictionì´ ë¹„ì–´ ìˆìŒ, ê¸°ë³¸ê°’ ì„¤ì •")
                action_prediction = {"predicted_actions": [], "predicted_questions": []}
            else:
                cleaned = (
                    raw_text.replace("```json", "")
                    .replace("```", "")
                    .strip()
                )
                action_prediction = json.loads(cleaned)
        except Exception as e:
            print(f"[ê²½ê³ ] JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
            print("ì›ë³¸ ì¶œë ¥:", repr(action_prediction_json))
            action_prediction = {"predicted_actions": [], "predicted_questions": []}
        print(f"[8] JSON íŒŒì‹± ì™„ë£Œ - {time.perf_counter() - t8:.2f}s")

        ## âœ… ì „ì²´ ì²˜ë¦¬ì‹œê°„ ì¶œë ¥
        total_time = time.perf_counter() - start_total
        print(f"\nâœ… ì „ì²´ ì‚¬ì´í´ ì™„ë£Œ - ì´ {total_time:.2f}ì´ˆ ì†Œìš”\n")

        ## ê²°ê³¼ ë°˜í™˜
        return {
            "representative_image": rep_img_path,
            "description": description_text,
            "cluster_size": len(all_imgs),
            "cluster_images": folder_context,
            "predicted_actions": action_prediction.get("predicted_actions", []),
            "predicted_questions": action_prediction.get("predicted_questions", [])
        }

    ## HistoryQA ê¸°ëŠ¥
    def answer_question(self, user_question: str):
        """
        ì‚¬ìš©ìì˜ ì§ˆë¬¸(user_question)ì— ëŒ€í•´, ìµœê·¼ ì´ë¯¸ì§€ ì„¤ëª… ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€ ìƒì„±.
        VectorDBì—ì„œ ìë™ìœ¼ë¡œ contextë¥¼ êµ¬ì„±í•©ë‹ˆë‹¤.
        """

        # 1ï¸âƒ£ ë²¡í„° DBê°€ ë¹„ì–´ìˆëŠ” ê²½ìš°
        if not self.db.metadata:
            print("[ê²½ê³ ] ë²¡í„° DBì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return "ë°ì´í„°ê°€ ì¶©ë¶„í•˜ì§€ ì•Šì•„ ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

        # 2ï¸âƒ£ ìµœê·¼ ì„¤ëª…(í˜„ì¬ ì»¨í…ìŠ¤íŠ¸)
        current_item = self.db.metadata[-1]
        current_context = current_item["text"]

        # 3ï¸âƒ£ ìµœê·¼ ê¸°ë¡ (ìµœê·¼ kê°œ)
        recent_items = self.db.get_recent(k=config["vectordb"]["recent_k"])
        recent_context = "\n\n".join([item["text"] for item in recent_items if item["id"] != current_item["id"]])

        # 4ï¸âƒ£ ìœ ì‚¬ ì»¨í…ìŠ¤íŠ¸ ê²€ìƒ‰
        embedding = self.embed_gen.generate_embedding(current_context)
        similar_results = self.db.search_vector(
            embedding,
            top_k=config["vectordb"]["search_top_k"],
            exclude_id=current_item["id"]
        )
        similar_context = "\n\n".join([r["metadata"]["text"] for r in similar_results])

        # 5ï¸âƒ£ íˆìŠ¤í† ë¦¬ ê¸°ë°˜ Q&A ìˆ˜í–‰
        answer = self.history_qa.answer(
            current_context=current_context,
            recent_context=recent_context,
            similar_context=similar_context,
            user_question=user_question
        )

        # 6ï¸âƒ£ ê²°ê³¼ ì¶œë ¥
        print("\n[ì§ˆë¬¸]")
        print(user_question)
        print("\n[ë‹µë³€]")
        print(answer)

        return answer


if __name__ == "__main__":
    service = IntegrationService()
    sample_dir = os.path.join(config["integration"]["sample_dir"])

    if not os.path.exists(sample_dir):
        raise FileNotFoundError(f"{sample_dir} í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤.")

    print(f"ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬: {sample_dir}\n")

    ## ë™ì¼ í´ë”ë¥¼ 3íšŒ ë°˜ë³µ ì²˜ë¦¬
    for i in range(3):
        print(f"\n=== [{i+1}íšŒì°¨ ì´ë¯¸ì§€ ì²˜ë¦¬ ì‹œì‘] ===")
        result = service.run_image_cycle(sample_dir)
        print(f"\n[{i+1}íšŒì°¨ í†µí•© ëª¨ë“ˆ ê²°ê³¼]")
        print(json.dumps(result, ensure_ascii=False, indent=2))

    ## ëª¨ë“  ì‚¬ì´í´ ì™„ë£Œ í›„ QA í…ŒìŠ¤íŠ¸ ìˆ˜í–‰
    print("\n============================")
    print("[HistoryQA í…ŒìŠ¤íŠ¸ ì‹œì‘]")
    user_question = "í˜„ì¬ ë‚˜ëŠ” ì–´ë–¤ ì¼ë“¤ì„ í•˜ê³  ìˆëŠ”ì§€ ì„¤ëª…í•´ì¤˜."
    answer = service.answer_question(user_question)
    print("\n[ìµœì¢… QA ê²°ê³¼]")
    print(answer)
